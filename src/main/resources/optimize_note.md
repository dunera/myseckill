### 环境
1. mac的IDEA中跑，并发量50，方法任何同步措施不加，会造成很大的数据上的偏差，50个并发请求，新订单会生成50个左右，但是
库存只会减少10个左右，造成问题的原因就是多线程并发修改库存数，造成多个线程读到的是相同的原库存值，修改之后，多个线程
互相覆盖了修改，这个应该跟可见性有关，试一下volatile修饰符会不会一定程度上缓解这个问题。

2. 加了volatile,并发50，第一次试没有错误，第二次调成并发100，生成订单100个，库存减少36，看来volatile并不能解决这个
问题。接下来试一下通过spring的事务管理，给秒杀方法加上事务，会不会有影响，能不能解决问题。后来发现方法上一直加着事务，
看来加事务也并不会解决问题，但是为什么呢？

3. 接下来试试synchronized关键字的作用
三次测试，并发量50，没有问题，
改成并发量100，库存减少92，订单生成100个，明显出问题了
加了synchronized，程序应该是没问题的了，但是，为啥还会造成数据的不一致呢，估计是数据库的问题，一会儿研究下数据库吧

4. 数据库默认的隔离级别，repeatable-read 会有并发修改的问题，改成serializable隔离级别，并发100，200下测试，
都没有出现数据不一致问题，说明当前的并发控制的问题发生在数据库层，于是将隔离级别改回repeatable-read，查询订单库存
的语句加上for update测试，1000的并发量下，也并没有发生问题。
发现这个for update是需要加在事务里的，相当于对读数据加了排它锁，但是mysql的默认隔离级别是repeatable-read，应该是
加了事务就会默认解决这个问题，但是发现并没有，还是需要手动加排它锁才会解决，为什么呢？  

简述造成上述问题的原因就是，并发读的时候，并没有任何地方加了锁限制，导致并发量大的时候可能有多个线程读到了相同的数据，
进而造成最终库存数减少的量少了，数据不一致的问题。

5. 如何使用缓存来对系统进行优化？
500的并发量，系统已经开始卡顿了，刷新页面的时候，会很久才会响应
缓存适用于读多写少的场景，需要思考一下都在哪些节点需要缓存的加入，如何通过缓存提高程序性能。
- 首先，每个秒杀单品的库存数值，用concurrentHashMap缓存起来，借用Spring初始化bean的方法，容器启动的时候，预热缓存。
秒杀操作之前，先去单机的缓存中拿到库存值判断，将超过库存之后的请求拦截在秒杀操作方法之前，可以减少很多对于商品和库存信息的查询。
- 还有其他的节点可以使用单机缓存的吗？

- LRU缓存的写法，参照durid的util，修改了一下，再次熟悉一下LinkedHashMap的原理

- 可以使用redis优化的场景都有哪些？
 - 热点数据缓存，秒杀商品列表数据可以缓存，因为秒杀前肯定会不停刷新，如果都刷到数据库一层，对数据库的压力影响太大
 - 库存数量缓存，秒杀成功用户标记，可以缓存，用来截断库存为空之后进来请求的用户，和已经成功秒杀的用户
 - 计数器，用来计算阻断的请求数，或者计算缓存失效的次数
 - 可以用来做消息队列

redis简单的缓存已经实现，接下来需要熟悉redis的事务的命令的使用，用熟redis，联想常用的应用场景，熟练各种面试相关问题。
rabbitMq的使用，和kafka的使用

消息队列的作用在于异步处理，创建订单的过程交给消息队列，然后程序直接返回，就可以提高并发的吞吐量，程序不需要同步等待创建完订单再返回。
优化重点在于，所有的请求都需要尽量在前端处理，只有新建订单的请求最后会操作数据库，而这一步也可以同过消息队列去进行异步，提高程序效率。



##### 